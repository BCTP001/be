{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fa6592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  title  \\\n",
      "0  [피치] 2022 프리즘 데일리 다이어리 (일간, 날짜형, 미니)   \n",
      "1      [세트] 킹 세종 더 그레이트 한글판 + 영문판 - 전2권   \n",
      "2                   블랙 쇼맨과 이름 없는 마을의 살인   \n",
      "3                            안녕, 소중한 사람   \n",
      "4    부지런한 사랑 (리커버) - 몸과 마음을 탐구하는 이슬아 글방   \n",
      "\n",
      "                                         description  \\\n",
      "0                                                NaN   \n",
      "1  세계적인 판타지 TV 드라마 시리즈 [스타트렉]의 작가, 프로듀서, 제작자인 '조 ...   \n",
      "2  매년 새 작품을 선보이는 히가시노 게이고가 새로운 시리즈로 발표하는 작품의 첫 권....   \n",
      "3  당신이 붙잡아야 할 소중함에 대한 모든 것. 안녕, 소중한 사람은 익숙함 뒤에 가려...   \n",
      "4  일간 이슬아 수필집 &lt;나는 울 때마다 엄마 얼굴이 된다&gt;의 이슬아 작가 ...   \n",
      "\n",
      "                          categoryName  \n",
      "0                 국내도서>달력/기타>출판사 제작 상품  \n",
      "1     국내도서>소설/시/희곡>판타지/환상문학>외국판타지/환상소설  \n",
      "2  국내도서>소설/시/희곡>추리/미스터리소설>일본 추리/미스터리소설  \n",
      "3                       국내도서>에세이>한국에세이  \n",
      "4                       국내도서>에세이>한국에세이  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "booktemp = pd.read_csv('booktemp.csv', sep=',', usecols=[1,5,11])\n",
    "print(booktemp.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26301cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame head:\n",
      "                                  title  \\\n",
      "0  [피치] 2022 프리즘 데일리 다이어리 (일간, 날짜형, 미니)   \n",
      "1      [세트] 킹 세종 더 그레이트 한글판 + 영문판 - 전2권   \n",
      "2                   블랙 쇼맨과 이름 없는 마을의 살인   \n",
      "3                            안녕, 소중한 사람   \n",
      "4    부지런한 사랑 (리커버) - 몸과 마음을 탐구하는 이슬아 글방   \n",
      "\n",
      "                                         description  \\\n",
      "0                                                NaN   \n",
      "1  세계적인 판타지 TV 드라마 시리즈 [스타트렉]의 작가, 프로듀서, 제작자인 '조 ...   \n",
      "2  매년 새 작품을 선보이는 히가시노 게이고가 새로운 시리즈로 발표하는 작품의 첫 권....   \n",
      "3  당신이 붙잡아야 할 소중함에 대한 모든 것. 안녕, 소중한 사람은 익숙함 뒤에 가려...   \n",
      "4  일간 이슬아 수필집 &lt;나는 울 때마다 엄마 얼굴이 된다&gt;의 이슬아 작가 ...   \n",
      "\n",
      "                          categoryname  \n",
      "0                 국내도서>달력/기타>출판사 제작 상품  \n",
      "1     국내도서>소설/시/희곡>판타지/환상문학>외국판타지/환상소설  \n",
      "2  국내도서>소설/시/희곡>추리/미스터리소설>일본 추리/미스터리소설  \n",
      "3                       국내도서>에세이>한국에세이  \n",
      "4                       국내도서>에세이>한국에세이  \n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1440 entries, 0 to 1439\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         1440 non-null   object\n",
      " 1   description   1370 non-null   object\n",
      " 2   categoryname  1440 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 33.9+ KB\n",
      "\n",
      "Loading Sentence Transformer model: all-MiniLM-L6-v2...\n",
      "Model loaded successfully.\n",
      "\n",
      "Generating embeddings for book titles and descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 45/45 [02:02<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated for 1440 books.\n",
      "\n",
      "Searching for books related to: 'science fiction adventure in space'\n",
      "\n",
      "--- Top Related Books ---\n",
      "                                                                    Title                                                                                                                                              Description                      Category  Similarity Score\n",
      "                                                                     1984                                                                                                                                                                      국내도서>소설/시/희곡>영미소설          0.243170\n",
      "                                                                     사냥꾼들 그래비티북스 GF;Gravity Fiction 시리즈 6호는 조나단 작가의 첫 장편SF 사냥꾼들이다. 종말 이후 세상을 배경으로 한 포스트 아포칼립스로, 식인종인 돌쟁이들에게 납치된 권 씨 영감의 딸을 찾아 길을 나서는 다섯 사냥꾼들의 종횡무진 모험담이 짜릿하게 펼쳐진다. 국내도서>소설/시/희곡>과학소설(SF)>한국 과학소설          0.230068\n",
      "[POD] 펠로폰네소스 전쟁사 2부 : The History of the Peloponnesian War. VOL. 02 (영문판)                                                                                                                                                                  국내도서>역사>테마로 보는 역사>전쟁사          0.160399\n",
      "------------------------------\n",
      "\n",
      "Searching for books related to: 'a thrilling mystery novel'\n",
      "\n",
      "--- Top Related Books ---\n",
      "      Title                                                                                                                                              Description                      Category  Similarity Score\n",
      "       1984                                                                                                                                                                      국내도서>소설/시/희곡>영미소설          0.212232\n",
      "       사냥꾼들 그래비티북스 GF;Gravity Fiction 시리즈 6호는 조나단 작가의 첫 장편SF 사냥꾼들이다. 종말 이후 세상을 배경으로 한 포스트 아포칼립스로, 식인종인 돌쟁이들에게 납치된 권 씨 영감의 딸을 찾아 길을 나서는 다섯 사냥꾼들의 종횡무진 모험담이 짜릿하게 펼쳐진다. 국내도서>소설/시/희곡>과학소설(SF)>한국 과학소설          0.148840\n",
      "꽃을 보듯 너를 본다                                                                                J.H Classic 2권. 나태주 시집. 나태주 시인의 작품 가운데에서 인터넷의 블로그나 트위터에 자주 오르내리는 시들만 모았다.            국내도서>소설/시/희곡>시>한국시          0.104083\n",
      "------------------------------\n",
      "\n",
      "Searching for books related to: 'cooking recipes for beginners'\n",
      "\n",
      "--- Top Related Books ---\n",
      "                                            Title                                                                                                                              Description                        Category  Similarity Score\n",
      "                                      처음 만나는 전자기학                        IT CookBook 358권. 이 책은 전자기학을 처음 배우는 공학계열 학생들을 위한 입문서로, 전자기학의 기초가 되는 벡터 해석부터 정전계, 정자계, 균일평면파까지 꼭 필요한 내용을 엄선하여 담았다. 국내도서>대학교재/전문서적>공학계열>전기전자공학>전자기학          0.340559\n",
      "                  호밀밭의 파수꾼 The Catcher in the Rye 영어 학습의 가장 큰 걸림돌인 어순을 완벽하게 마스터할 수 있도록 구성한 문장 확장 프로그램. 한국인이 사랑하는 고전의 문장을 영어 학습에서 가장 많이 쓰는 기초 패턴으로 재구성해, 책장을 넘길 때마다 문장이 길어지도록 만든 딕테이션 학습서다.                   국내도서>외국어>영어독해          0.148557\n",
      "[세트] 그릿 GRIT (100쇄 기념 리커버 에디션) + 어린이를 위한 그릿 - 전2권                                                                                 '그릿 GRIT (100쇄 기념 리커버 에디션)'과 '어린이를 위한 그릿'으로 구성된 세트 상품이다.            국내도서>자기계발>창의적사고/두뇌계발          0.141115\n",
      "------------------------------\n",
      "\n",
      "Searching for books related to: 'historical drama about ancient Rome'\n",
      "\n",
      "--- Top Related Books ---\n",
      "                                                                    Title                                                                                                    Description              Category  Similarity Score\n",
      "                          로마 시티 Rome City - The Illustrated Story of Rome 시간과 이야기가 겹겹이 쌓인 도시, 로마를 여행하는 가장 근사한 방법. 일러스트레이터·컨셉아티스트이자 로마·역사 매니아인 지은이는 일러스트 3백여 컷과 더불어 로마의 이야기를 흥미진진하게 풀어낸다.       국내도서>역사>서양사>로마사          0.366764\n",
      "[POD] 펠로폰네소스 전쟁사 2부 : The History of the Peloponnesian War. VOL. 02 (영문판)                                                                                                                국내도서>역사>테마로 보는 역사>전쟁사          0.248929\n",
      "                                                                     1984                                                                                                                    국내도서>소설/시/희곡>영미소설          0.177379\n",
      "------------------------------\n",
      "\n",
      "Searching for books related to: 'children's story about animals'\n",
      "\n",
      "--- Top Related Books ---\n",
      "                                                                    Title                                                                                                                                            Description               Category  Similarity Score\n",
      "                                             우리는 마약을 모른다 - 교양으로 읽는 마약 세계사              마약의 역사를 짚어보면, 마약은 인류가 시작되는 순간부터 인류와 함께했다. 테렌스 맥케나는 고대 인류가 ‘실로시빈’이라는 환각물질이 포함된 버섯을 섭취하면서 어떤 특이점을 넘어서게 되었다는, ‘마약 원숭이(stuned ape)’ 가설을 제시한다.        국내도서>인문학>교양 인문학          0.171578\n",
      "[POD] 펠로폰네소스 전쟁사 2부 : The History of the Peloponnesian War. VOL. 02 (영문판)                                                                                                                                                         국내도서>역사>테마로 보는 역사>전쟁사          0.152087\n",
      "                                                              두 번째 지구는 없다 방송계의 대표적인 ‘언어 천재’, ‘뇌섹남’으로 통하는 타일러 라쉬의 첫 단독 도서이다. 기후위기 해결은 타일러의 오랜 꿈으로, 환경은 그가 오랫동안 품어온 화두다. 타일러는 2016년부터 WWF(세계자연기금) 홍보대사로 활동하며 환경 문제의 심각성을 알려왔다.  \\n 국내도서>사회과학>환경/생태문제>환경문제          0.134663\n",
      "------------------------------\n",
      "\n",
      "Searching for books related to: 'fantasy world with magic and dragons'\n",
      "\n",
      "--- Custom Query Results ---\n",
      "                                    Title                                                                                                          Description                     Category  Similarity Score\n",
      "                           초망 - 항우에서 한신까지 우리에게 『초한지楚漢誌』의 배경으로 잘 알려진 중국 진한秦漢 교체기에 대한 육중한 역사서 두 권이 출간되었다. 리카이위안李開元의 『진붕秦崩: 진시황에서 유방까지』와 『초망楚亡: 항우에서 한신까지』가 그것이다. 국내도서>역사>중국사>중국고대사(선사시대~진한시대)          0.213136\n",
      "[큰글자도서] 이덕일의 한국통사 3  - 다시 찾는 7,000년 우리 역사                                                                                                                                    국내도서>역사>한국사 일반          0.132447\n",
      "                                     동물농장                                                                                                                          국내도서>어린이>초등 전학년>동화/명작/고전          0.120233\n",
      "         [세트] 올리브 키터리지 + 다시, 올리브 세트 - 전2권                                                                                  '올리브 키터리지', '다시, 올리브'로 구성된 세트 상품이다.            국내도서>소설/시/희곡>영미소설          0.119433\n",
      "                                  명상록 행복론                                                                                                                        국내도서>인문학>서양철학>고대철학>고대철학 일반          0.118862\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your CSV file\n",
    "CSV_FILE_PATH = 'booktemp.csv'\n",
    "# Pre-trained Sentence Transformer model to use for generating embeddings\n",
    "# 'all-MiniLM-L6-v2' is a good balance of performance and speed.\n",
    "# You can explore other models like 'all-mpnet-base-v2' for potentially better accuracy\n",
    "# but higher resource usage.\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "# Number of top results to return\n",
    "TOP_N_RESULTS = 5\n",
    "\n",
    "# --- Load Data ---\n",
    "# Ensure the CSV file exists in the same directory as your script,\n",
    "# or provide the full path.\n",
    "try:\n",
    "    booktemp = pd.read_csv(CSV_FILE_PATH, sep=',', usecols=[1, 5, 11])\n",
    "    # Rename columns for easier access\n",
    "    booktemp.columns = ['title', 'description', 'categoryname']\n",
    "    print(\"Original DataFrame head:\")\n",
    "    print(booktemp.head())\n",
    "    print(\"\\nDataFrame info:\")\n",
    "    booktemp.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{CSV_FILE_PATH}' was not found.\")\n",
    "    print(\"Please make sure 'booktemp.csv' is in the same directory as your script.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "# Handle missing descriptions or titles by filling them with empty strings.\n",
    "# This prevents errors during embedding generation.\n",
    "booktemp['description'] = booktemp['description'].fillna('')\n",
    "booktemp['title'] = booktemp['title'].fillna('')\n",
    "\n",
    "# Combine title and description into a single text field for better context\n",
    "# when calculating similarity against a query.\n",
    "booktemp['combined_text'] = booktemp['title'] + \" \" + booktemp['description']\n",
    "\n",
    "# --- Model Loading ---\n",
    "print(f\"\\nLoading Sentence Transformer model: {MODEL_NAME}...\")\n",
    "try:\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model '{MODEL_NAME}': {e}\")\n",
    "    print(\"Please ensure you have an internet connection or the model is cached locally.\")\n",
    "    print(\"You might need to install sentence-transformers: pip install sentence-transformers\")\n",
    "    exit()\n",
    "\n",
    "# --- Generate Embeddings ---\n",
    "# This is the most computationally intensive step.\n",
    "# It converts all combined texts into numerical vectors.\n",
    "print(\"\\nGenerating embeddings for book titles and descriptions...\")\n",
    "# Use a try-except block to catch potential issues during embedding\n",
    "try:\n",
    "    corpus_embeddings = model.encode(booktemp['combined_text'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "    print(f\"Embeddings generated for {len(corpus_embeddings)} books.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during embedding generation: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- AI Function: Find Most Related Book ---\n",
    "def find_most_related_book(query: str, top_n: int = TOP_N_RESULTS):\n",
    "    \"\"\"\n",
    "    Finds the most related book based on the query by comparing it\n",
    "    to the combined title and description of books.\n",
    "\n",
    "    Args:\n",
    "        query (str): The input query string.\n",
    "        top_n (int): The number of top related books to return.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the top_n most related books\n",
    "                      with their similarity scores.\n",
    "    \"\"\"\n",
    "    if not query:\n",
    "        print(\"Query cannot be empty.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"\\nSearching for books related to: '{query}'\")\n",
    "\n",
    "    # Encode the query into an embedding\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity between the query embedding and all book embeddings\n",
    "    # util.cos_sim returns a tensor of similarity scores\n",
    "    cosine_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "\n",
    "    # Get the top N scores and their indices\n",
    "    # torch.topk returns values (scores) and indices\n",
    "    top_results = torch.topk(cosine_scores, k=top_n)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        book_index = idx.item() # Get the actual index from the tensor\n",
    "        results.append({\n",
    "            'Title': booktemp.loc[book_index, 'title'],\n",
    "            'Description': booktemp.loc[book_index, 'description'],\n",
    "            'Category': booktemp.loc[book_index, 'categoryname'],\n",
    "            'Similarity Score': score.item() # Convert tensor score to Python float\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the results for easy viewing\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"science fiction adventure in space\",\n",
    "        \"a thrilling mystery novel\",\n",
    "        \"cooking recipes for beginners\",\n",
    "        \"historical drama about ancient Rome\",\n",
    "        \"children's story about animals\"\n",
    "    ]\n",
    "\n",
    "    for q in queries:\n",
    "        related_books = find_most_related_book(q, top_n=3)\n",
    "        if not related_books.empty:\n",
    "            print(\"\\n--- Top Related Books ---\")\n",
    "            print(related_books.to_string(index=False)) # Use to_string to print full DataFrame\n",
    "            print(\"-\" * 30)\n",
    "        else:\n",
    "            print(f\"\\nNo related books found for query: '{q}'\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    # You can also test with your own custom query\n",
    "    my_custom_query = \"fantasy world with magic and dragons\"\n",
    "    custom_results = find_most_related_book(my_custom_query, top_n=5)\n",
    "    if not custom_results.empty:\n",
    "        print(\"\\n--- Custom Query Results ---\")\n",
    "        print(custom_results.to_string(index=False))\n",
    "        print(\"-\" * 30)\n",
    "    else:\n",
    "        print(f\"\\nNo related books found for custom query: '{my_custom_query}'\")\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ea58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
